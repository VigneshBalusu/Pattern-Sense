{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cajn93Hs52kc","executionInfo":{"status":"ok","timestamp":1751109407382,"user_tz":-330,"elapsed":24638,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"71bf57e8-6137-4f5f-c0fe-911af6ccab2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MVZWBCwoPrH6","executionInfo":{"status":"ok","timestamp":1751109893747,"user_tz":-330,"elapsed":30,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}}},"outputs":[],"source":["zip_path = \"/content/drive/MyDrive/archive.zip\"\n","extract_path = \"/content/fashion-pattern-images\""]},{"cell_type":"code","execution_count":13,"metadata":{"id":"rIYh-BjqPs4X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751109920376,"user_tz":-330,"elapsed":25730,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"af520420-63cf-4f01-b7d8-e2dd43156765"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Extracted successfully to: /content/fashion-pattern-images\n"]}],"source":["import zipfile\n","import os\n","\n","# Create target directory if it doesn't exist\n","os.makedirs(extract_path, exist_ok=True)\n","\n","# Extract\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(\"/content/\")  # Change to `extract_path` if needed\n","\n","# Optional: Check if extraction succeeded\n","if os.path.exists(extract_path):\n","    print(f\" Extracted successfully to: {extract_path}\")\n","else:\n","    print(\" Extraction failed or folder name doesn't match.\")"]},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","\n","# Paths\n","original_dataset_dir = '/content/fashion-pattern-images'  # your extracted folder\n","base_dir = '/content/data'  # base path for train/val\n","train_dir = os.path.join(base_dir, 'train')\n","val_dir = os.path.join(base_dir, 'val')\n","\n","# Create directories\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(val_dir, exist_ok=True)\n","\n","# Split ratio\n","split_ratio = 0.8  # 80% train, 20% val\n","\n","# Split each class\n","for class_name in os.listdir(original_dataset_dir):\n","    class_path = os.path.join(original_dataset_dir, class_name)\n","    if not os.path.isdir(class_path):\n","        continue\n","\n","    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n","    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n","\n","    images = os.listdir(class_path)\n","    random.shuffle(images)\n","    split_idx = int(len(images) * split_ratio)\n","\n","    for image in images[:split_idx]:\n","        src = os.path.join(class_path, image)\n","        dst = os.path.join(train_dir, class_name, image)\n","        shutil.copyfile(src, dst)\n","\n","    for image in images[split_idx:]:\n","        src = os.path.join(class_path, image)\n","        dst = os.path.join(val_dir, class_name, image)\n","        shutil.copyfile(src, dst)\n","\n","print(\" Dataset successfully split into train/ and val/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61351cNQB0fB","executionInfo":{"status":"ok","timestamp":1751109925298,"user_tz":-330,"elapsed":2818,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"59a174f0-536e-4df7-b15b-0d7041dec47a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":[" Dataset successfully split into train/ and val/\n"]}]},{"cell_type":"code","source":["import os\n","from collections import Counter\n","\n","dataset_dir = '/content/data/train'\n","class_counts = Counter()\n","\n","for class_name in os.listdir(dataset_dir):\n","    class_path = os.path.join(dataset_dir, class_name)\n","    if os.path.isdir(class_path):\n","        image_count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","        class_counts[class_name] = image_count\n","\n","for class_name, count in sorted(class_counts.items()):\n","    print(f\"{class_name}: {count} images\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egekQJ4EYpFo","executionInfo":{"status":"ok","timestamp":1751109926812,"user_tz":-330,"elapsed":53,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"253e0e32-8c21-4af9-a824-6bf340771f7d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["argyle: 441 images\n","camouflage: 455 images\n","checked: 450 images\n","dot: 488 images\n","floral: 464 images\n","geometric: 443 images\n","gradient: 448 images\n","graphic: 446 images\n","houndstooth: 448 images\n","leopard: 448 images\n","lettering: 441 images\n","muji: 484 images\n","paisley: 448 images\n","snake_skin: 449 images\n","snow_flake: 467 images\n","stripe: 476 images\n","tropical: 451 images\n","zebra: 507 images\n","zigzag: 456 images\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    'data/train',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    'data/val',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5btoQ4YZRwf","executionInfo":{"status":"ok","timestamp":1751109928613,"user_tz":-330,"elapsed":260,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"a139b732-1b8f-4e74-b371-475f8bf63b1b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8710 images belonging to 19 classes.\n","Found 2188 images belonging to 19 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n","\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","base_model.trainable = False\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dropout(0.3)(x)\n","x = Dense(128, activation='relu')(x)\n","x = Dropout(0.2)(x)\n","predictions = Dense(19, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMw-2tz8aJxZ","executionInfo":{"status":"ok","timestamp":1751109930215,"user_tz":-330,"elapsed":823,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"d3f952ee-5e99-447d-e516-fc1bec86a834"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-17-2110589417.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True),\n","    ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n","]"],"metadata":{"id":"2HjIwIbDaTQF","executionInfo":{"status":"ok","timestamp":1751109931069,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!mkdir -p \"/content/drive/MyDrive/fabric_model\""],"metadata":{"id":"0pOl0nTJaXog","executionInfo":{"status":"ok","timestamp":1751109935777,"user_tz":-330,"elapsed":88,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["!ls best_model.keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRrTAwCs-Bsk","executionInfo":{"status":"ok","timestamp":1751109937094,"user_tz":-330,"elapsed":160,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"6cd71b72-c7ec-42c9-9a87-3eaa0026dc2c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'best_model.keras': No such file or directory\n"]}]},{"cell_type":"code","source":["model_save_path = '/content/drive/MyDrive/fabric_model/best_model.keras'"],"metadata":{"id":"fS4gPoiuN4F-","executionInfo":{"status":"ok","timestamp":1751109938007,"user_tz":-330,"elapsed":36,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["model.save(model_save_path)\n","print(\"✅ Model saved to Google Drive successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wngPESTDN9--","executionInfo":{"status":"ok","timestamp":1751109939443,"user_tz":-330,"elapsed":482,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"268ee110-6e27-40eb-fc9e-9753cacace28"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model saved to Google Drive successfully.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","model = load_model(\"/content/drive/MyDrive/fabric_model/best_model.keras\")"],"metadata":{"id":"8AG4wpYb-LgD","executionInfo":{"status":"ok","timestamp":1751109977567,"user_tz":-330,"elapsed":2118,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10a444d2-60eb-4ad0-f82b-ba7af7386635"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    epochs=30,\n","    validation_data=val_generator,\n","    callbacks=callbacks\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"id":"FM5ZUt0oOSBB","executionInfo":{"status":"error","timestamp":1751110005529,"user_tz":-330,"elapsed":25265,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"9d5244a4-096e-431b-c837-17966297b604"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m 24/273\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 509ms/step - accuracy: 0.1021 - loss: 3.1931"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-25-4180402113.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model.save(model_save_path)\n","print(\"✅ Model saved to Google Drive successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzfF7s2tObBM","executionInfo":{"status":"ok","timestamp":1751106514069,"user_tz":-330,"elapsed":505,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"73e013aa-a803-4a81-d874-2ff786de1a0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model saved to Google Drive successfully.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","\n","# Load your trained model\n","model = load_model(\"/content/drive/MyDrive/fabric_model/best_model.keras\")\n","\n","# Class labels\n","class_labels = [\n","    \"argyle\", \"camouflage\", \"checked\", \"dot\", \"floral\", \"geometric\",\n","    \"gradient\", \"graphic\", \"houndstooth\", \"leopard\", \"lettering\",\n","    \"muji\", \"paisley\", \"snake_skin\", \"snow_flake\", \"stripe\", \"tropical\",\n","    \"zebra\", \"zigzag\"\n","]\n","\n","# Load and preprocess image\n","img = image.load_img(\"/content/paisely1.jpeg\", target_size=(224, 224))  # Make sure size matches training\n","img_array = image.img_to_array(img) / 255.0\n","img_array = np.expand_dims(img_array, axis=0)\n","\n","# Predict\n","prediction = model.predict(img_array)[0]  # shape: (19,)\n","\n","# Print confidence scores for each class\n","print(\"\\n📊 Confidence for all fabric patterns:\")\n","for label, prob in zip(class_labels, prediction):\n","    print(f\"{label:15s}: {prob * 100:.2f}%\")\n","\n","# Print top prediction\n","predicted_index = int(np.argmax(prediction))\n","print(\"\\n✅ Most likely class:\", class_labels[predicted_index])\n","print(\"🔍 Confidence:\", round(prediction[predicted_index] * 100, 2), \"%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"al9mKSFp-Pho","executionInfo":{"status":"ok","timestamp":1751109662424,"user_tz":-330,"elapsed":2245,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"83371a0c-564d-432c-d43f-5dfbdce2cdd0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","\n","📊 Confidence for all fabric patterns:\n","argyle         : 0.00%\n","camouflage     : 0.00%\n","checked        : 0.00%\n","dot            : 0.00%\n","floral         : 0.76%\n","geometric      : 9.59%\n","gradient       : 0.00%\n","graphic        : 14.10%\n","houndstooth    : 0.00%\n","leopard        : 0.00%\n","lettering      : 0.52%\n","muji           : 0.00%\n","paisley        : 14.59%\n","snake_skin     : 0.00%\n","snow_flake     : 4.58%\n","stripe         : 0.00%\n","tropical       : 55.84%\n","zebra          : 0.00%\n","zigzag         : 0.01%\n","\n","✅ Most likely class: tropical\n","🔍 Confidence: 55.84 %\n"]}]},{"cell_type":"code","source":["model.trainable = True\n","# Optionally freeze the first few layers if needed:\n","for layer in model.layers[:100]:\n","    layer.trainable = False\n","\n","# Recompile with a lower learning rate\n","from tensorflow.keras.optimizers import Adam\n","model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"9TDXAlSz-dYT","executionInfo":{"status":"ok","timestamp":1751109804459,"user_tz":-330,"elapsed":30,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Assumes `model` is your trained model and `val_generator` is your validation data generator\n","\n","# Get true labels and predictions\n","val_generator.reset()\n","pred_probs = model.predict(val_generator, verbose=1)\n","y_pred = np.argmax(pred_probs, axis=1)\n","y_true = val_generator.classes\n","class_labels = list(val_generator.class_indices.keys())  # Get class label names\n","\n","# Generate confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(14, 10))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.xticks(rotation=45)\n","plt.yticks(rotation=0)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"uXY2yr4cRtkb","executionInfo":{"status":"error","timestamp":1751109837675,"user_tz":-330,"elapsed":2505,"user":{"displayName":"Vignesh B","userId":"05177312843890434048"}},"outputId":"18bfc4c8-35d9-44bb-aa07-2577dc374510"},"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'val_generator' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-11-2501738112.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get true labels and predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'val_generator' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Or2SGTH8R5hH"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyORs7YoT8YS/qlPsWExmQuv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}